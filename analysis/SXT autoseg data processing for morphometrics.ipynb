{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtifffile\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtff\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxlsxwriter\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tff\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxtdata = os.getcwd() \n",
    "sxtdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Raw Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input must be name of structure, capitalized (\"Cell\", \"Vacuole\", \"Nucleus\", \"LD\")\n",
    "# output: 5 dataframes (raw all strains, processed all strains, WT, vph1-GFP, vac14), data saved to Excel file w 5 sheets\n",
    "# processing: scale msmts according to voxel size, apply size filter, reset index\n",
    "\n",
    "def metrics_df(struc):\n",
    "    raw_3Dsuite =  pd.read_csv(sxtdata + \"/3D Suite Measurements/Raw/\" + struc + \" 3D Suite Results.csv\") \n",
    "    num_rows = raw_3Dsuite.shape[0]\n",
    "    num_cols = raw_3Dsuite.shape[1]\n",
    "    cols = raw_3Dsuite.columns.tolist()\n",
    "    \n",
    "    # create a list of object names by merging cell name and object ID number  \n",
    "    print(raw_3Dsuite['Label'][1])\n",
    "    \n",
    "    objIDs_list = []\n",
    "    for org in range(num_rows):\n",
    "    #     print(org)\n",
    "        objID = raw_3Dsuite['Label'][org] + \"_\" + str(raw_3Dsuite['LabelObj'][org])\n",
    "    #     print(objID)\n",
    "        objIDs_list.append(objID)\n",
    "\n",
    "    print(\"Objects list:\", len(objIDs_list))\n",
    "    \n",
    "    # condense list of objects by removing repeats\n",
    "    objIDs_cond = []\n",
    "\n",
    "    for x in objIDs_list:\n",
    "    #     print(x)\n",
    "        if x not in objIDs_cond:\n",
    "            objIDs_cond.append(x)\n",
    "    \n",
    "    print(\"Unique Objects:\", len(objIDs_cond)) \n",
    "    \n",
    "    # create a condensed list of cell IDs to match objIDs_cond\n",
    "    cellIDs_cond = []\n",
    "\n",
    "    for obj in objIDs_cond:\n",
    "        cellIDs_cond.append(obj.split('.tiff_')[0])\n",
    "    \n",
    "    print(\"Cells:\", len(cellIDs_cond))\n",
    "    \n",
    "    # create a dictionary with cell and object IDs\n",
    "    cond_3Dsuite = dict({'Cell ID':cellIDs_cond,'Object ID':objIDs_cond})\n",
    "\n",
    "    for c in cols:\n",
    "        colvals = raw_3Dsuite[c]\n",
    "        nonzero_colvals = list(filter(lambda x: x !=0,colvals)) # use lambda function to remove zeros\n",
    "    #     print(len(nonzero_colvals))\n",
    "    \n",
    "        # get rid of empty space in 3D suite output - number of nonzero values should match the number of objects \n",
    "        # this will remove some number of parameter columns which for some reason have a different number of values\n",
    "        if len(nonzero_colvals) == len(objIDs_cond):\n",
    "#             print(c, len(nonzero_colvals))\n",
    "            cond_3Dsuite.update({c:nonzero_colvals})\n",
    "    \n",
    "    # check which parameter columns were excluded, should at least include index, Label, and LabelObj)\n",
    "    removed_cols = [x for x in cols if x not in list(cond_3Dsuite.keys())]\n",
    "    print(\"Removed: \", removed_cols)\n",
    "            \n",
    "    struc_df = pd.DataFrame(cond_3Dsuite)\n",
    "#     print(struc_df)\n",
    "    \n",
    "    # scale measurements according to known pixel sizes\n",
    "    \n",
    "    # create dictionary where keys are pix sizes (floats), values are cell IDs (lists of strings)\n",
    "    pix_sizes = [30,35.31,36.8,30.23]\n",
    "    pix30 = [\"1359\",\"1026\",\"1208\",\"1360\"] + \\\n",
    "            [\"1463_\"+str(x) + \"_\" for x in range(1,18)] + \\\n",
    "            [\"1467_\"+str(x) + \"_\" for x in range(2,12)] + \\\n",
    "            [\"1475_\"+str(x) + \"_\" for x in range(1,10)] + \\\n",
    "            [\"1464_\"+str(x) + \"_\" for x in range(1,19)]\n",
    "    pix35_31 = [\"1463_\"+str(x) + \"_\" for x in range(18,27)] + \\\n",
    "               [\"1467_\"+str(x) + \"_\" for x in range(12,17)] + \\\n",
    "               [\"1475_\"+str(x) + \"_\" for x in range(11,19)] + \\\n",
    "               [\"1464_\"+str(x) + \"_\" for x in range(20,29)] \n",
    "\n",
    "    pix36_8 = [\"1463_\"+str(x) + \"_\" for x in range(30,35)] \n",
    "    pix30_23 = ['1361_']\n",
    "\n",
    "    pix_dict = dict({30:pix30, 35.31:pix35_31, 36.8:pix36_8, 30.23:pix30_23})\n",
    "    # list(pix_dict.keys())\n",
    "    \n",
    "    # compare cell IDs against pix_size values, convert, create new lists to replace struc_df columns\n",
    "    vol_scaled = []\n",
    "    c_x_scaled = []\n",
    "    c_y_scaled = []\n",
    "    c_z_scaled = []\n",
    "    SA_scaled = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for c in struc_df['Cell ID']:\n",
    "    #     print(c)\n",
    "        for ps in pix_sizes: # ps = integer pixel size\n",
    "    #         print(c,ps)\n",
    "            for p in pix_dict[ps]: # p = list of string IDs\n",
    "    #             print(c,ps,i)\n",
    "                if p in c: # if cell identifier pd matches cell ID value, scale measurements, make lists\n",
    "    #                 print(i, c, ps, p)\n",
    "                    # volume\n",
    "                    c_vol = struc_df.at[i,'Volume(Pix)']\n",
    "                    scaled_c_vol = (c_vol*(ps*1e3))/(1e9)\n",
    "                    vol_scaled.append(scaled_c_vol)\n",
    "    #                 print(c_vol,scaled_c_vol)\n",
    "\n",
    "                    # centroid coordinates\n",
    "                    c_x = struc_df.at[i,'CX(pix)']\n",
    "                    scaled_c_x = (c_x*ps)/1e3\n",
    "                    c_x_scaled.append(scaled_c_x)\n",
    "    #                 print(c,scaled_c_x)\n",
    "\n",
    "                    c_y = struc_df.at[i,'CY(pix)']\n",
    "                    scaled_c_y = (c_y*ps)/1e3\n",
    "                    c_y_scaled.append(scaled_c_y)\n",
    "\n",
    "                    c_z = struc_df.at[i,'CZ(pix)']\n",
    "                    scaled_c_z = (c_z*ps)/1e3\n",
    "                    c_z_scaled.append(scaled_c_z)\n",
    "\n",
    "                    # surface area\n",
    "                    c_SA = struc_df.at[i,'Surface(Pix)']\n",
    "                    scaled_SA = (c_SA*(ps*1e2))/1e6\n",
    "                    SA_scaled.append(scaled_SA) \n",
    "        i+=1\n",
    "\n",
    "    # replace unscaled struc_df columns w scaled lists\n",
    "    struc_df_scl = struc_df.drop(['Volume(Unit)'], axis  = 1)\n",
    "    struc_df_scl.insert(3,'Volume (um^3)', vol_scaled)\n",
    "    \n",
    "    struc_df_scl.drop(['CX(unit)'], axis  = 1)\n",
    "    struc_df_scl.insert(7,'CX (um)', c_x_scaled)\n",
    "    \n",
    "    struc_df_scl.drop(['CY(unit)'], axis  = 1)\n",
    "    struc_df_scl.insert(8,'CY (um)', c_y_scaled)\n",
    "    \n",
    "    struc_df_scl.drop(['CZ(unit)'], axis  = 1)\n",
    "    struc_df_scl.insert(9,'CZ (um)', c_z_scaled)\n",
    "    \n",
    "    struc_df_scl.drop(['Surface(Unit)'], axis  = 1)\n",
    "    struc_df_scl.insert(11,'Surface (um)', SA_scaled)\n",
    "    \n",
    "\n",
    "    # apply size filter to organelles - see notes 4/11/23 for threshold rationale\n",
    "    if struc == 'Vacuole':\n",
    "        struc_df_scl_filt = struc_df_scl.loc[struc_df_scl['Volume (um^3)']>0.3]\n",
    "    elif struc == 'Nucleus':\n",
    "        struc_df_scl_filt = struc_df_scl.loc[struc_df_scl['Volume (um^3)']>0.4]\n",
    "    else:\n",
    "        struc_df_scl_filt = struc_df_scl\n",
    "        \n",
    "    # sort the table by Object IDs so all objects from the same cell are consecutive; \n",
    "    # reset index to start at 0; creates new 'index' col w original values\n",
    "    struc_df_scl_filt_sort = struc_df_scl_filt.sort_values('Object ID')\n",
    "    \n",
    "    # filter out WT\n",
    "    wt1 = struc_df_scl_filt_sort[struc_df_scl_filt_sort['Cell ID'].str.contains('BY471A')]\n",
    "    wt2 = struc_df_scl_filt_sort[struc_df_scl_filt_sort['Cell ID'].str.contains('BY4741A')]\n",
    "    wt3 = struc_df_scl_filt_sort[struc_df_scl_filt_sort['Cell ID'].str.contains('BY471_wt')]\n",
    "    WT = pd.concat([wt1,wt2,wt3]).reset_index()\n",
    "\n",
    "    # filter out vph1-GFP\n",
    "    vph1GFP = struc_df_scl_filt_sort[struc_df_scl_filt_sort['Cell ID'].str.contains('vph')].reset_index()\n",
    "\n",
    "    # filter out vac14\n",
    "    vac14 = struc_df_scl_filt_sort[struc_df_scl_filt_sort['Cell ID'].str.contains('VaCL4')].reset_index()\n",
    "    \n",
    "    # save data to multi-sheet Excel file (raw data, condensed, then split by strain)\n",
    "    dflist = [raw_3Dsuite, struc_df_scl_filt_sort, WT, vph1GFP, vac14]\n",
    "    dfnames = ['Raw All Strains', \"Processed All Strains\", \"WT\", \"VPH1-GFP\", \"vac14\"]\n",
    "    Excelwriter = pd.ExcelWriter(struc +  \" 3D Suite.xlsx\", engine = 'xlsxwriter')\n",
    "    \n",
    "    for i,df in enumerate(dflist):\n",
    "        df.to_excel(Excelwriter, sheet_name = dfnames[i], index=False)\n",
    "#     Excelwriter.save()\n",
    "\n",
    "    return(struc_df_scl_filt_sort.reset_index(), WT, vph1GFP, vac14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run metrics_df for all structures & strains\n",
    "\n",
    "# Cell\n",
    "cell = metrics_df(\"Cell\")\n",
    "cell_all = cell[0]\n",
    "cell_WT = cell[1]\n",
    "cell_vph1GFP = cell[2]\n",
    "cell_vac14 = cell[3]\n",
    "len(cell_all.columns.tolist())\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "cell_all\n",
    "\n",
    "# Vacuole\n",
    "vac = metrics_df(\"Vacuole\")\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "vac_all = vac[0]\n",
    "vac_WT = vac[1]\n",
    "vac_vph1GFP = vac[2]\n",
    "vac_vac14 = vac[3]\n",
    "# vac_all\n",
    "\n",
    "# Nucleus\n",
    "nuc = metrics_df(\"Nucleus\")\n",
    "nuc_all = nuc[0]\n",
    "nuc_WT = nuc[1]\n",
    "nuc_vph1GFP = nuc[2]\n",
    "nuc_vac14 = nuc[3]\n",
    "# nuc_all['Volume (um^3)']\n",
    "\n",
    "# LD\n",
    "LD = metrics_df(\"LD\")\n",
    "LD_all = LD[0]\n",
    "LD_WT = LD[1]\n",
    "LD_vph1GFP = LD[2]\n",
    "LD_vac14 = LD[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out cells which do not have a nucleus or any vacuoles\n",
    "\n",
    "# len(nuc_all['Cell ID']) #493\n",
    "# len(cell_all['Cell ID']) #510\n",
    "# len(vac_all['Cell ID']) #507\n",
    "# len(LD_all['Cell ID']) #2614\n",
    "\n",
    "# first, split the cellIDs to normalize them, since they end with _CELL, _NUC, etc\n",
    "nuc_cellIDs = [x.split('multi')[0] for x in list(nuc_all['Cell ID'])]\n",
    "cell_cellIDs = [x.split('multi')[0] for x in list(cell_all['Cell ID'])]\n",
    "vac_cellIDs = [x.split('multi')[0] for x in list(vac_all['Cell ID'])]\n",
    "LD_cellIDs = [x.split('multi')[0] for x in list(LD_all['Cell ID'])]\n",
    "# cell_cellIDs\n",
    "\n",
    "# list of cells excluding those w no nuc or vac\n",
    "# this fills a list with cell IDs that are also found in the nuc and vac lists\n",
    "cell_cellIDs_filt = [x for x in cell_cellIDs if x in nuc_cellIDs and x in vac_cellIDs]\n",
    "# len(cell_cellIDs_filt) #490\n",
    "\n",
    "# lists of included cells - =IDs in each structure list that match the filtered cellIDs\n",
    "cells_inc = [x for x in cell_cellIDs if x in cell_cellIDs_filt]\n",
    "nuc_inc = [x for x in nuc_cellIDs if x in cell_cellIDs_filt]\n",
    "vac_inc = [x for x in vac_cellIDs if x in cell_cellIDs_filt]\n",
    "LD_inc = [x for x in LD_cellIDs if x in cell_cellIDs_filt]\n",
    "\n",
    "# there should be at least as many items in each organelle list as in the cell list; nuclei should match\n",
    "# print((len(cells_inc),len(nuc_inc),len(vac_inc),len(LD_inc))) #(490, 490, 492, 2557)\n",
    "# if cells_inc == nuc_inc:\n",
    "#     print(True) # cell and nucleus lists are exactly the same!\n",
    "\n",
    "# lists of excluded cells - the ones missing nuclei/vacuoles\n",
    "cells_exc = [x for x in cell_cellIDs if x not in cell_cellIDs_filt]\n",
    "nuc_exc = [x for x in nuc_cellIDs if x not in cell_cellIDs_filt]\n",
    "vac_exc = [x for x in vac_cellIDs if x not in cell_cellIDs_filt]\n",
    "LD_exc = [x for x in LD_cellIDs if x not in cell_cellIDs_filt]\n",
    "all_exc = set(cells_exc + nuc_exc + vac_exc + LD_exc)\n",
    "\n",
    "# print(cells_exc)\n",
    "\n",
    "# print('Cells: ', cells_exc[0])\n",
    "#' \\n Nuclei: ', nuc_exc, ' \\n Vacuoles: ', vac_exc)\n",
    "# print((len(cells_exc),len(nuc_exc),len(vac_exc),len(LD_exc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply size filters to exclude nonspecific organelles; remove all structures for those cells\n",
    "\n",
    "def filter_metrics(struc_all): \n",
    "    # all_exc\n",
    "    struc_all_filt = struc_all\n",
    "#     print(struc_all_filt['Volume (um^3)'][0], len(struc_all_filt['Volume (um^3)']))\n",
    "\n",
    "    i=0\n",
    "    for x in struc_all['Cell ID']:\n",
    "        for y in all_exc:\n",
    "            if y in x:\n",
    "#                 print(i,x,y)\n",
    "    #             print(cell_all.loc[i])\n",
    "                struc_all_filt = struc_all_filt.drop(i)\n",
    "        i+=1\n",
    "#     print(struc_all_filt['Volume (um^3)'][0], len(struc_all_filt['Volume (um^3)']))\n",
    "\n",
    "\n",
    "    # sort the table by Object IDs so all objects from the same cell are consecutive; \n",
    "    # reset index to start at 0; creates new 'index' col w original values\n",
    "    struc_all_filt_sort = struc_all_filt.sort_values('Object ID')    \n",
    "#     print(struc_all_filt['Volume (um^3)'][0], len(struc_all_filt['Volume (um^3)']))\n",
    "\n",
    "    # filter out WT\n",
    "    struc_wt1 = struc_all_filt_sort[struc_all_filt_sort['Cell ID'].str.contains('BY471A')]\n",
    "    struc_wt2 = struc_all_filt_sort[struc_all_filt_sort['Cell ID'].str.contains('BY4741A')]\n",
    "    struc_wt3 = struc_all_filt_sort[struc_all_filt_sort['Cell ID'].str.contains('BY471_wt')]\n",
    "    struc_WT = pd.concat([struc_wt1,struc_wt2,struc_wt3])\n",
    "#     print(struc_WT['Volume (um^3)'][0], len(struc_all_filt['Volume (um^3)']))\n",
    "\n",
    "\n",
    "    # filter out vph1-GFP\n",
    "    struc_vph1GFP = struc_all_filt_sort[struc_all_filt_sort['Cell ID'].str.contains('vph')]\n",
    "    # filter out vac14\n",
    "    struc_vac14 = struc_all_filt_sort[struc_all_filt_sort['Cell ID'].str.contains('VaCL4')]\n",
    "    \n",
    "    return(struc_all_filt_sort, struc_WT, struc_vph1GFP, struc_vac14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filtered dataframes for each structure_all/strain\n",
    "cell_filt = filter_metrics(cell_all)\n",
    "cell_filt_all = cell_filt[0].reset_index()\n",
    "cell_filt_WT= cell_filt[1].reset_index()\n",
    "cell_filt_vph1gfp = cell_filt[2].reset_index()\n",
    "cell_filt_vac14 = cell_filt[3].reset_index()\n",
    "\n",
    "vac_filt = filter_metrics(vac_all)\n",
    "vac_filt_all = vac_filt[0].reset_index()\n",
    "vac_filt_WT= vac_filt[1].reset_index()\n",
    "vac_filt_vph1gfp = vac_filt[2].reset_index()\n",
    "vac_filt_vac14 = vac_filt[3].reset_index()\n",
    "\n",
    "nuc_filt = filter_metrics(nuc_all)\n",
    "nuc_filt_all = nuc_filt[0].reset_index()\n",
    "nuc_filt_WT= nuc_filt[1].reset_index()\n",
    "nuc_filt_vph1gfp = nuc_filt[2].reset_index()\n",
    "nuc_filt_vac14 = nuc_filt[3].reset_index()\n",
    "\n",
    "LD_filt = filter_metrics(LD_all)\n",
    "LD_filt_all = LD_filt[0].reset_index()\n",
    "LD_filt_WT= LD_filt[1].reset_index()\n",
    "LD_filt_vph1gfp = LD_filt[2].reset_index()\n",
    "LD_filt_vac14 = LD_filt[3].reset_index()\n",
    "\n",
    "# save excel files by strain\n",
    "all_strucs = [cell_filt[0], vac_filt[0],nuc_filt[0],LD_filt[0]]\n",
    "WT_strucs = [cell_filt[1], vac_filt[1],nuc_filt[1],LD_filt[1]]\n",
    "vph1gfp_strucs = [cell_filt[2], vac_filt[2],nuc_filt[2],LD_filt[2]]\n",
    "vac14_strucs = [cell_filt[3], vac_filt[3],nuc_filt[3],LD_filt[3]]\n",
    "\n",
    "df_lists = [all_strucs, WT_strucs, vph1gfp_strucs, vac14_strucs]\n",
    "strains = [\"All Strains\", \"WT\", \"VPH1-GFP\", \"vac14\"]\n",
    "structures = ['Cell', \"Vacuole\", \"Nucleus\", \"LD\"]\n",
    "\n",
    "for i,strain_df in enumerate(df_lists):\n",
    "    writer = pd.ExcelWriter(strains[i]+ \" 3D Suite_Filtered.xlsx\", engine = 'xlsxwriter')\n",
    "\n",
    "    for j,df in enumerate(strain_df):\n",
    "#         print(j)\n",
    "        df.to_excel(writer, sheet_name = structures[j], index = False)\n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that each filtered list contains the same cells\n",
    "\n",
    "cell_filt_set = list(set(cell_filt[0]['Cell ID']))\n",
    "# len(cell_filt_set)\n",
    "nuc_filt_set = list(set(nuc_filt[0]['Cell ID']))\n",
    "# len(nuc_filt_set)\n",
    "# nuc_filt_set\n",
    "vac_filt_set = list(set(vac_filt[0]['Cell ID']))\n",
    "# len(vac_filt_set)\n",
    "LD_filt_set = list(set(LD_filt[0]['Cell ID']))\n",
    "len(LD_filt_set)\n",
    "\n",
    "cell_filt_set.sort() == LD_filt_set.sort()\n",
    "# pd.DataFrame(cell_filt_set,nuc_filt_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filtering vacuoles - excluding nonspecific too-small objects\n",
    "\n",
    "# # plot WT vacuole volume histogram\n",
    "# WTvac_vol_hist = plt.hist(vac_filt[0]['Volume (um^3)'], bins = 50,label='All Vac')\n",
    "# plt.title('All Strains Vacuole Volume')\n",
    "# plt.xlabel('Volume (um^3)')\n",
    "\n",
    "# # output figures directory\n",
    "# # os.getcwd()\n",
    "\n",
    "# figs_dir = 'C:\\\\Users\\\\Mary\\\\Documents\\\\Shared folder\\\\Data\\\\SXT\\\\ML segmentation tiffs\\\\Final set for analysis\\\\3D Suite Measurements\\\\Figures\\\\'\n",
    "# plt.savefig(figs_dir + 'all vac_vol_hist_bin30.png',format = 'png')\n",
    "\n",
    "# # vac_WT.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum vacuole volumes per cell\n",
    "# create new vac volumes dict that sums the vols in the value for the cell key\n",
    "\n",
    "# populate a dictionary w each key being cell ID from vac_filt_set\n",
    "vac_sum_dict = {}\n",
    "for i in vac_filt_set:\n",
    "    vac_sum_dict.update({i:[0]})\n",
    "# len(vac_sum_dict) # 490 cells\n",
    "len(vac_filt_all['Object ID']) # 492 vacuoles\n",
    "\n",
    "i = 0\n",
    "for v in vac_filt_all['Object ID']: # for each vacuole object\n",
    "#     print(i, v.split('.tiff_')[0])\n",
    "    vac_sum_dict_key = v.split('.tiff_')[0] # get the obj ID to match the cell ID = dictionary key\n",
    "    vac_sum_dict_val = vac_sum_dict[vac_sum_dict_key]  # the corresponding dict value starts as an empty list\n",
    "#     print(i,v,vac_sum_dict_key,vac_sum_dict_val)\n",
    "#     if vac_sum_dict_key in vac_sum_dict.keys(): # check that the keys match\n",
    "#         print(i, vac_sum_dict_key)\n",
    "\n",
    "    obj_vol = vac_filt_all.at[i,'Volume (um^3)'] # <--- why is this line giving me a key error?\n",
    "#     print(i)\n",
    "# # #     testlist.append(obj_vol)\n",
    "# # #     print(testlist)\n",
    "\n",
    "#     print(v, vac_sum_dict_val[0]+obj_vol)\n",
    "#     print(v, vac_sum_dict_val[0])\n",
    "    vac_sum_dict[vac_sum_dict_key][0]+=obj_vol\n",
    "#     vac_sum_dict[vac_sum_dict_key].append(obj_vol)\n",
    "    \n",
    "    ## find cells with more than 1 vacuole:\n",
    "##     BY471A_1026_1_2_pre_rec_20_multi_bin_VAC\n",
    "##     BY471_vphl_GFP_1208_2_2_pre_rec_15_multi_bin_VAC\n",
    "#     for x in list(vac_sum_dict.keys()):\n",
    "#         if len(vac_sum_dict[x]) > 2:\n",
    "#             print(x)\n",
    "    i+=1\n",
    "    \n",
    "# vac_sum_dict['BY471A_1026_1_2_pre_rec_20_multi_bin_VAC'] # should be 2.1+0.56 = 2.66... and it is!\n",
    "# len(vac_sum_dict) # 490, matching # cells\n",
    "# vac_sum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cells with multiple vacuoles\n",
    "vac_sum_dict['BY471A_1026_1_2_pre_rec_20_multi_bin_VAC'].append(3.5)\n",
    "# vac_sum_dict['BY471A_1026_1_2_pre_rec_20_multi_bin_VAC']\n",
    "# x for x in vac_filt_all['Object ID'] if\n",
    "for x in list(vac_sum_dict.keys()):\n",
    "    if len(vac_sum_dict[x]) > 1:\n",
    "        print(len(vac_sum_dict[x]))\n",
    "\n",
    "vac_sum_dict['BY471A_1026_1_2_pre_rec_20_multi_bin_VAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create correctly ordered list of vacuole sum volumes to add to volume df\n",
    "vac_sum_vols_list = [x[0] for x in list(vac_sum_dict.values())]\n",
    "len(vac_sum_vols_list)\n",
    "\n",
    "vac_sum_df = pd.DataFrame()\n",
    "vac_sum_df['Cell ID'] = vac_sum_dict.keys()\n",
    "vac_sum_df['Vacuole Volume (um^3)'] = vac_sum_vols_list\n",
    "\n",
    "vac_sum_df = vac_sum_df.sort_values('Cell ID')\n",
    "vac_sum_df = vac_sum_df.reset_index()\n",
    "vac_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum LD volumes per cell - repeat the above process for LDs (unfiltered)\n",
    "# create new LD volumes dict that sums the vols in the value for the cell key\n",
    "\n",
    "# populate a dictionary w each key being cell ID from LD_filt_set\n",
    "LD_sum_dict = {}\n",
    "for i in LD_filt_set:\n",
    "    LD_sum_dict.update({i:[0]})\n",
    "# len(LD_sum_dict) # 490 cells\n",
    "# len(LD_filt_all['Object ID']) # 2557 LDs\n",
    "\n",
    "i = 0\n",
    "for ld in LD_filt_all['Object ID']: # for each vacuole object\n",
    "#     print(i, ld.split('.tiff_')[0])\n",
    "    LD_sum_dict_key = ld.split('.tiff_')[0] # get the obj ID to match the cell ID = dictionary key\n",
    "    LD_sum_dict_val = LD_sum_dict[LD_sum_dict_key]  # the corresponding dict value starts as an empty list\n",
    "#     print(i,ld,LD_sum_dict_key,LD_sum_dict_val)\n",
    "\n",
    "# check that the keys match\n",
    "#     if LD_sum_dict_key in LD_sum_dict.keys(): \n",
    "#         print(i, LD_sum_dict_key)\n",
    "\n",
    "    obj_vol = LD_filt_all.at[i,'Volume (um^3)'] \n",
    "#     print(i)\n",
    "# # #     testlist.append(obj_vol)\n",
    "# # #     print(testlist)\n",
    "\n",
    "# #     print(v, vac_sum_dict_val[0]+obj_vol)\n",
    "# #     print(v, vac_sum_dict_val[0])\n",
    "    LD_sum_dict[LD_sum_dict_key][0]+=obj_vol\n",
    "    i+=1\n",
    "    \n",
    "# LD_sum_dict\n",
    "\n",
    "# create correctly ordered list of vacuole sum volumes to add to volume df\n",
    "LD_sum_vols_list = [x[0] for x in list(LD_sum_dict.values())]\n",
    "LD_sum_vols_list\n",
    "\n",
    "LD_sum_df = pd.DataFrame()\n",
    "LD_sum_df['Cell ID'] = LD_sum_dict.keys()\n",
    "LD_sum_df['LD Volume (um^3)'] = LD_sum_vols_list\n",
    "\n",
    "LD_sum_df = LD_sum_df.sort_values('Cell ID')\n",
    "LD_sum_df = LD_sum_df.reset_index()\n",
    "LD_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged volume table for scaling analysis for each strain\n",
    "all_vols_df = pd.DataFrame({'Cell ID':cell_filt_all['Cell ID'],'Cell Volume (um^3)':cell_filt_all['Volume (um^3)']})\n",
    "all_vols_df['Nucleus Volume (um^3)']=nuc_filt_all['Volume (um^3)']\n",
    "all_vols_df['Vacuole Sum Volume (um^3)']=vac_sum_df['Vacuole Volume (um^3)']\n",
    "all_vols_df['LD Sum Volume (um^3)']=LD_sum_df['LD Volume (um^3)']\n",
    "# avg LD vol/cell\n",
    "# #LDs/cell\n",
    "# stdev LD vol/cell\n",
    "all_vols_df['N+V'] = all_vols_df['Nucleus Volume (um^3)']+all_vols_df['Vacuole Sum Volume (um^3)']\n",
    "all_vols_df['Sum Organelles'] = all_vols_df['Nucleus Volume (um^3)']+all_vols_df['Vacuole Sum Volume (um^3)']+all_vols_df['LD Sum Volume (um^3)']\n",
    "\n",
    "# calculate various versions of cytoplasm\n",
    "\n",
    "all_vols_df['Cyto_N'] = all_vols_df['Cell Volume (um^3)']-all_vols_df['Nucleus Volume (um^3)']\n",
    "all_vols_df['Cyto_V'] = all_vols_df['Cell Volume (um^3)']-all_vols_df['Vacuole Sum Volume (um^3)']\n",
    "all_vols_df['Cyto_LD'] = all_vols_df['Cell Volume (um^3)']-all_vols_df['LD Sum Volume (um^3)']\n",
    "all_vols_df['Cyto_NV'] = all_vols_df['Cell Volume (um^3)']-all_vols_df['N+V']\n",
    "all_vols_df['Cyto_Organelles'] = all_vols_df['Cell Volume (um^3)']-all_vols_df['Sum Organelles']\n",
    "\n",
    "# calculate ratios\n",
    "\n",
    "all_vols_df['VCratio'] = all_vols_df['Vacuole Sum Volume (um^3)']/all_vols_df['Cell Volume (um^3)']\n",
    "all_vols_df['NCratio'] = all_vols_df['Nucleus Volume (um^3)']/all_vols_df['Cell Volume (um^3)']\n",
    "all_vols_df['LDCratio'] = all_vols_df['LD Sum Volume (um^3)']/all_vols_df['Cell Volume (um^3)']\n",
    "all_vols_df['VNCratio'] = all_vols_df['N+V']/all_vols_df['Cell Volume (um^3)']\n",
    "all_vols_df['OrganellesCellratio'] = all_vols_df['Sum Organelles']/all_vols_df['Cell Volume (um^3)']\n",
    "all_vols_df['Cyto_OrganellesCellratio'] = all_vols_df['Cyto_Organelles']/all_vols_df['Cell Volume (um^3)']\n",
    "\n",
    "all_vols_df['VCytoratio'] = all_vols_df['Vacuole Sum Volume (um^3)']/all_vols_df['Cyto_V']\n",
    "all_vols_df['NCytoratio'] = all_vols_df['Nucleus Volume (um^3)']/all_vols_df['Cyto_N']\n",
    "all_vols_df['LDCytoratio'] = all_vols_df['LD Sum Volume (um^3)']/all_vols_df['Cyto_LD']\n",
    "all_vols_df['VNCytoratio'] = all_vols_df['N+V']/all_vols_df['Cyto_NV']\n",
    "all_vols_df['OrganellesCytoratio'] = all_vols_df['Sum Organelles']/all_vols_df['Cyto_Organelles']\n",
    "\n",
    "# all_vols_df['VCratio']\n",
    "all_vols_df\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split all_vols_df by strain\n",
    "\n",
    "# filter out WT\n",
    "wt1_vols_df = all_vols_df[all_vols_df['Cell ID'].str.contains('BY471A')]\n",
    "wt2_vols_df = all_vols_df[all_vols_df['Cell ID'].str.contains('BY4741A')]\n",
    "wt3_vols_df = all_vols_df[all_vols_df['Cell ID'].str.contains('BY471_wt')]\n",
    "WT_vols_df = pd.concat([wt1_vols_df,wt2_vols_df,wt3_vols_df])\n",
    "\n",
    "\n",
    "# filter out vph1-GFP\n",
    "vph1GFP_vols_df = all_vols_df[all_vols_df['Cell ID'].str.contains('vph')]\n",
    "# filter out vac14\n",
    "vac14_vols_df = all_vols_df[all_vols_df['Cell ID'].str.contains('VaCL4')]\n",
    "\n",
    "# print(all_vols_df['VCratio'].describe())\n",
    "# print(WT_vols_df['VCratio'].describe())\n",
    "# print(vph1GFP_vols_df['VCratio'].describe())\n",
    "\n",
    "# save vols dfs\n",
    "# sxtdata\n",
    "# all_Excelwriter = pd.ExcelWriter(sxtdata +'/3D Suite Measurements/Volumes and ratios/all_volumes_ratios.xlsx', engine = 'xlsxwriter')\n",
    "# # all_Excelwriter\n",
    "# all_vols_df.to_excel(all_Excelwriter, index=False)\n",
    "# all_Excelwriter.save()\n",
    "\n",
    "# WT_Excelwriter = pd.ExcelWriter(sxtdata +'/3D Suite Measurements/Volumes and ratios/WT_volumes_ratios.xlsx', engine = 'xlsxwriter')\n",
    "# # WT_Excelwriter\n",
    "# WT_vols_df.to_excel(WT_Excelwriter, index=False)\n",
    "# WT_Excelwriter.save()\n",
    "\n",
    "# vph1GFP_Excelwriter = pd.ExcelWriter(sxtdata +'/3D Suite Measurements/Volumes and ratios/vph1GFP_volumes_ratios.xlsx', engine = 'xlsxwriter')\n",
    "# # vph1GFP_Excelwriter\n",
    "# vph1GFP_vols_df.to_excel(vph1GFP_Excelwriter, index=False)\n",
    "# vph1GFP_Excelwriter.save()\n",
    "\n",
    "vac14_Excelwriter = pd.ExcelWriter(sxtdata +'/3D Suite Measurements/Volumes and ratios/vac14_volumes_ratios.xlsx', engine = 'xlsxwriter')\n",
    "# vac14_Excelwriter\n",
    "vac14_vols_df.to_excel(vac14_Excelwriter, index=False)\n",
    "vac14_Excelwriter.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
